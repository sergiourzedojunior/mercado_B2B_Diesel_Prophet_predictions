{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Setup Inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Bibliotecas utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# getting linked services connection string \n",
        "adls_account_name = 'stedlk01dtandev'  \n",
        "sas_key = r\"9999\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Definições gerais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "blob_container_name = 'general' # replace with your container name\n",
        "blob_relative_path_raw = 'raw/mercado_potencial/ibge/' # replace with your relative folder path\n",
        "blob_relative_path_enriched = 'enriched/mercado_potencial/ibge/' # replace with your relative folder path\n",
        "linked_service_raw = 'LS_ADLS_RAW_01' # replace with your linked service name\n",
        "linked_service_enriched = 'LS_ADLS_ENRICHED_01' # replace with your linked service name\n",
        "\n",
        "\n",
        "ls_raw = mssparkutils.credentials.getPropertiesAll(linked_service_raw)\n",
        "ls_enriched = mssparkutils.credentials.getPropertiesAll(linked_service_enriched)\n",
        "\n",
        "converter_dic_raw = json.loads(ls_raw)\n",
        "converter_dic_enriched = json.loads(ls_enriched)\n",
        "\n",
        "#coletando o endpoint\n",
        "end_point_raw = (converter_dic_raw['Endpoint'].split(\"/\"))[2]\n",
        "end_point_enriched = (converter_dic_enriched['Endpoint'].split(\"/\"))[2]\n",
        "\n",
        "#Utilizado na leitura via metodo mssparkutils\n",
        "abfss_path_raw = 'abfss://%s@%s/%s' % (blob_container_name, end_point_raw, blob_relative_path_raw)\n",
        "abfss_path_enriched = 'abfss://%s@%s/%s' % (blob_container_name, end_point_enriched, blob_relative_path_enriched)\n",
        "\n",
        "#Utilizados na leitura e gravação dos arquivos via metodo (read_csv ou to_parquet)\n",
        "#storage_options = {'linked_service':ls_enriched}\n",
        "#dir_raw  = 'abfss://general/raw/mercado_potencial/ibge/'\n",
        "#dir_enriched = 'abfss://general/enriched/mercado_potencial/ibge/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções de utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ajuste_IBGE (data):\n",
        "    \"\"\"Ajusta o .json da API do IBGE.\n",
        "\n",
        "        Ajusta o .json captrado direntamente da API do IBGE com nas \n",
        "        diversas estruturas e dníveis de dados. \n",
        "        \n",
        "    Parâmetros\n",
        "    ----------\n",
        "    data : .json \n",
        "        Arquivo em formato .json a ser processado.\n",
        "    \n",
        "    Retorno\n",
        "    -------\n",
        "    pdResult : pd.DataFrame\n",
        "        Dataframe de fornato 'long table' com os dados distribuidos em\n",
        "        tabela de largura fixa, com 6(seis) variáveis.\n",
        "\n",
        "        'data': datatime\n",
        "            Período em mês, trimestre ou ano do dado  \n",
        "        'valor': object\n",
        "            Valor da informação - algumas series vem strings '...'\n",
        "            deve-se tratar fora, assim como transformar .astype(float)\n",
        "        'categoria_1': str\n",
        "            Nível 1 da categoria dos dados\n",
        "        'categoria_2': str\n",
        "            Nível 2 da categoria dos dados\n",
        "        'variavel': str\n",
        "            Nome da variável\n",
        "        'local': str\n",
        "            Agregração geográfica da Variável\n",
        "    \n",
        "    Notes\n",
        "    -----\n",
        "    API do IBGE: https://servicodados.ibge.gov.br/api/docs/agregados?versao=3#api-bq\n",
        "\n",
        "    \"\"\"\n",
        "    pdResult = pd.DataFrame()\n",
        "    for i in range(len(data)): # se tiver mais de uma variável requerida\n",
        "        result = data[i]['resultados']\n",
        "        for j in range(len(result)):\n",
        "            aux = pd.json_normalize(result[j]['series'][0]['serie'])\n",
        "            local = result[j]['series'][0]['localidade']['nome']\n",
        "            if len(result[j]['classificacoes']) > 0: # existe mais de uma estrutura - categoria e a série de valores\n",
        "                nome_cat1 = pd.json_normalize(result[j]['classificacoes'][0]['categoria']).iat[0, 0] # nome da categoria 1\n",
        "                nome_cat2 = '-'\n",
        "                if len(result[j]['classificacoes']) > 1:\n",
        "                    nome_cat2 = pd.json_normalize(result[j]['classificacoes'][1]['categoria']).iat[0, 0] # nome da categoria 2\n",
        "            else: # se =1 não existe categoria somente a serie de valores\n",
        "                nome_cat1 = '-'\n",
        "                nome_cat2 = '-'\n",
        "\n",
        "            pd_aux = pd.DataFrame({'data': aux.T.index,\n",
        "                                   'valor': aux.to_numpy()[0], # algumas series vem strings '...' deve tratar fora, assim como transformar .astype(float)\n",
        "                                   'categoria_1':nome_cat1,\n",
        "                                   'categoria_2':nome_cat2,\n",
        "                                   'variavel':data[i]['variavel'],\n",
        "                                   'local':local})\n",
        "            pdResult = pd.concat([pdResult, pd_aux], ignore_index=True)\n",
        "\n",
        "    return(pdResult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wide_table_IBGE(df):\n",
        "    \"\"\"Transforma dados do IBGE de long para wide table  .\n",
        "\n",
        "        Transforma as tabelas long table do IBGE em tabelas de formato\n",
        "        wide.\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "    df : pd.DataFrame \n",
        "        DataFrame a ser processado .\n",
        "    \n",
        "    Retorno\n",
        "    -------\n",
        "    df_out: pd.DataFrame\n",
        "        Datafrme dos dados transformados\n",
        "    \"\"\"\n",
        "    df_out = df.copy()\n",
        " \n",
        "    # Transformando o RowData em ColData usando o groupby Todas as tabelas do IBGE\n",
        "    # tem a mesma estrutura \n",
        "    df_out = df_out.groupby(['data',\n",
        "                       'categoria_1',\n",
        "                       'categoria_2',\n",
        "                       'variavel'])['valor'].sum()\n",
        "\n",
        "    # Ajustando os dados com o unstack os levels são os níveis em ordem de ajuste\n",
        "    df_out = df_out.unstack(level=[3,2,1])\n",
        "\n",
        "    # ajuste do nome das colunas | flat_index conjugas os niveis do indice\n",
        "    # outras funções que poderiam ser utilizadas .droplevel() .get_level_values()\n",
        "    df_out.columns = df_out.columns.to_flat_index()\n",
        "\n",
        "    return(df_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def serie_temporal_IBGE(df, nm_cols):\n",
        "    \"\"\"Adequa os dados coletados em serie de tempo.\n",
        "\n",
        "        Transforma as tabelas em tabelas de series temporal,\n",
        "        renomeando as colunas originais com nomenclatura mais acessivel.\n",
        "   \n",
        "    Parâmetros\n",
        "    ----------\n",
        "    df : pd.DataFrame \n",
        "        DataFrame com dados em formato long table a ser processado.\n",
        "    nm_cols: list of strings\n",
        "        Lista com os nomes das colunas a serem renomeadas.\n",
        "    \n",
        "    Retorno\n",
        "    -------\n",
        "    df_out: pd.DataFrame\n",
        "        Datafrme dos dados ajustados, coluna com a informação de data \n",
        "        ajustada para o formato 'Ano mes' setada como índice e removendo\n",
        "        '...' dado não existente por pd.NaN\n",
        "    \"\"\"\n",
        "    df_out = wide_table_IBGE(df)\n",
        "    df_out.index = pd.to_datetime(df_out.index, format='%Y%m')\n",
        "    df_out = pd.DataFrame(df_out) #precisa do pd.DataFrame pq se tiver só uma coluna retorna uma série\n",
        "    df_out.columns = nm_cols\n",
        "    df_out = df_out[df_out != '...'] # substitui os valores não existentes por NaN\n",
        "    df_out = df_out.astype(float)\n",
        "\n",
        "    return(df_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Execução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Leitura e ajuste dos dados na camada row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#lista todos os arquivos no diretório\n",
        "files = [i.path for i in mssparkutils.fs.ls(abfss_path_raw)]\n",
        "\n",
        "# ler e trata dos dados do IBGE\n",
        "ipca = ajuste_IBGE(pd.read_json(files[0], lines = True, encoding='utf-8', storage_options = {'linked_service' : linked_service_raw})[0]) # MENSAL\n",
        "pib  = ajuste_IBGE(pd.read_json(files[1], lines = True, encoding='utf-8', storage_options = {'linked_service' : linked_service_raw})[0]) # TRIMESTRAL\n",
        "pms  = ajuste_IBGE(pd.read_json(files[2], lines = True, encoding='utf-8', storage_options = {'linked_service' : linked_service_raw})[0]) # MENSAL\n",
        "pnad = ajuste_IBGE(pd.read_json(files[3], lines = True, encoding='utf-8', storage_options = {'linked_service' : linked_service_raw})[0]) # MENSAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Ajustes iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#In[9]: AJUSTE DOS FORMATOS DAS DATAS DO IBGE\n",
        "\n",
        "#ajuste da data do PIB Trimestral\n",
        "pib['data'] = pib['data'].str[:-2] + \\\n",
        "              pib['data'].str[-2:].replace({'01':'03',\n",
        "                                            '02':'06',\n",
        "                                            '03':'09',\n",
        "                                            '04':'12'}) \n",
        "\n",
        "#ajuste das das datas de periodo mensal\n",
        "x = [pnad, ipca, pms, pib]\n",
        "for i in x:\n",
        "    i['data'] = pd.to_datetime(i['data'], format='%Y%m')\n",
        "del(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Ajustes finais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1 = serie_temporal_IBGE(pms, ['PMS_ReceitaNomSer_CG', 'PMS_ReceitaNomSer_TP', 'PMS_VolumeSer_CG','PMS_VolumeSer_TP'])\n",
        "x2 = serie_temporal_IBGE(pnad, ['PNAD_Desocupacao'])\n",
        "x3 = serie_temporal_IBGE(ipca, ['IPCA_VarMensal'])\n",
        "x4 = serie_temporal_IBGE(pib, ['PIB_Exportacao','PIB_CaptalFixo','PIB_Importacao','PIB_PrecoMercado'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Upsampling dos dados trimestrais em dados mensais do PIB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Foi utilizada a função linear por ser mais fidedifno ao comportamento das curvas\n",
        "# resample Linear para o Inicio do Mês dos dados que eram Trimestrais\n",
        "\n",
        "x4l = x4.resample('MS').interpolate(method='linear') # MS - Month Start\n",
        "\n",
        "# codigo exemplo comparando varios tipos de interpolação - \n",
        "# Escolhido o LINEAR por manter fidedignidade o movimento original\n",
        "#xl = x['PIB_Exportacao'].resample('MS').interpolate(method='linear')\n",
        "#xc = x['PIB_Exportacao'].resample('MS').interpolate(method='cubic')\n",
        "#xs = x['PIB_Exportacao'].resample('MS').interpolate(method='spline', order=3)\n",
        "#pd.concat([xl, xc, xs], axis=1).loc['2021':'2022'].plot(color=['blue','red','green'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Agrupando dados do IBGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Agrupando dados do IBGE a serem utilizados no estudo\n",
        "# Dados já em formato float e com datatime unificados\n",
        "pd_mesIBGE = pd.concat([x1, x2, x3,x4l], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Definição do período inicial das séries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# definindo o periodo inicial da série\n",
        "pd_mesIBGE = pd_mesIBGE['2012':]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Salvando dados mensais IBGE na camada eriched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# SALVA TABELA EM FORMATO .parquet\n",
        "pd_mesIBGE.to_parquet(abfss_path_enriched + 'IBGE_mes.parquet', \n",
        "                     storage_options = {'linked_service':linked_service_enriched})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Acesso à documentação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(ajuste_IBGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(wide_table_IBGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(serie_temporal_IBGE)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Modelo de Volumes de Diesel Vendidos a Usinas Sucroalcooleiras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Setup Inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Carregando linhas com configurações iniciais já escritas em notebook base\n",
        "\n",
        "No bloco de comando \"%run\" não pode ter nenhum outra linha de comando ou comentário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%run nb00_Setup_Usinas{}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Funções"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def mape(real, pred):\n",
        "    '''\n",
        "        Função que calcula o erro absoluto percentual médio.\n",
        "    \n",
        "    Parâmetros\n",
        "    ----------\n",
        "        real: pd.DataFrame\n",
        "            Dataframe com os dados reais\n",
        "        pred: pd.DataFrame\n",
        "            Dataframe com os dados previstos\n",
        "    Result:\n",
        "    --------\n",
        "        mape: float\n",
        "            erro absoluto percentual médio \n",
        "    '''\n",
        "\n",
        "    mape = np.mean(np.abs((pred - real) / real))\n",
        "    return(mape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def mape_ano(df):\n",
        "    '''\n",
        "        Função que calcula o erro absoluto percentual médio anual\n",
        "    \n",
        "    Parâmetros\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dataframe com os dados reais e previstos no periodo\n",
        "    Result:\n",
        "    --------\n",
        "        result: pd.DataFrame\n",
        "            data frame contendo o erro absoluto percentual médio de cada ano existende em df\n",
        "    '''\n",
        "    result = pd.DataFrame()\n",
        "    for i in df['ds'].dt.year.unique()[:-2]:\n",
        "        y = df[df['ds'].dt.strftime('%Y')==str(i)]['y']\n",
        "        yhat = df[df['ds'].dt.strftime('%Y')==str(i)]['yhat']\n",
        "        result = result.append({'Ano':str(i), 'Mape':mape(y,yhat)}, ignore_index=True)\n",
        "    return(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def ajuste_dados(df, df2, filtro='REGIAO3', agrega=True, regiao='Brasil'): \n",
        "    '''\n",
        "        Auxilia no ajuste dos dados preliminar a previsão dos modelos.\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dataframe com os dados de histórico de vendas\n",
        "        df2: pd.DataFrame\n",
        "            Dataframe com os dados auxiliares de safra\n",
        "        filtro: string\n",
        "            Nome da variável(coluna) que formou o agrupamento regional a ser considerado no processamento\n",
        "        agrega: Bolean\n",
        "            Variável que define se os dados auxiliares irão compor o modelo(True) ou não(False)\n",
        "        regiao: string\n",
        "            Nome da região a ser considerada no processamento\n",
        "    Result:\n",
        "    --------\n",
        "        hist: pd.DataFrame\n",
        "           Dataframe com os dados prontos para inserir nos modelos de previsão  \n",
        "    '''\n",
        "    try:\n",
        "        if (regiao!='Brasil'):\n",
        "            df = df[df[filtro]==regiao]\n",
        "            df2 = df2[df2[filtro]==regiao]\n",
        "    except Exception as e:\n",
        "        return(help(ajuste_dados))\n",
        "\n",
        "        \n",
        "    hist = df.groupby(['Data','IMP'])['Vol_Total'].sum().reset_index()\n",
        "    hist = hist.pivot_table(values='Vol_Total', index='Data', columns='IMP').reset_index()\n",
        "    hist.rename_axis(None, axis=1, inplace=True)\n",
        "    hist.columns = ['ds','Vol_Cliente', 'Vol_NaoCliente']\n",
        "    hist['y'] = hist[['Vol_Cliente', 'Vol_NaoCliente']].sum(axis=1)\n",
        "\n",
        "    if agrega==True:\n",
        "        sf = df2.pivot_table(values='sugarcane_crop', index=['data_apuracao'], columns=['product'], aggfunc='sum').reset_index()\n",
        "        sf = sf.resample('MS',on='data_apuracao').sum().reset_index()\n",
        "        hist = hist.merge(sf, how='left', left_on='ds', right_on='data_apuracao')\n",
        "        hist.drop('data_apuracao', axis=1, inplace=True)\n",
        "        hist.dropna(inplace=True)                                                   # remove os NaN para o modelo poder performar na presença de dados\n",
        "    return(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def processa_modelo(df_orig, df_modelo):\n",
        "    '''\n",
        "        Auxilia no processamento do modelo, por meio da função modelo_final em nb00_Setup_Usinas.\n",
        "            \n",
        "    Parâmetros\n",
        "    ----------\n",
        "        df_orig: pd.DataFrame\n",
        "            Dataframe com as componentes do Tamanho de Mercado (Clientes e Não Clientes)\n",
        "        df_modelo: pd.DataFrame\n",
        "            Dataframe com os dados a serem ajustados pelos modelos prophet, \n",
        "                contendo ou não regressores auxiliares\n",
        "    Result:\n",
        "    --------\n",
        "        pred: pd.DataFrame\n",
        "            data freme de previsão associados as componentes do Tamanho de Mercado \n",
        "                (Clientes e Não Clientes)\n",
        "        model: Prophet.model\n",
        "            Modelo prophet ajustado (fitted)\n",
        "        pri: int\n",
        "            posição (index) do último dado real, início da previsão \n",
        "    '''\n",
        "    \n",
        "    pred, model = modelo_final(df_modelo)\n",
        "    \n",
        "    pred = pred.merge(df_orig[['ds', 'Vol_Cliente','Vol_NaoCliente']], how='left', on='ds')        # agregando as variáveis originais\n",
        "\n",
        "    pri = pred.loc[pd.isna(pred['y']), :].index[0]-1                                                # Ultimo dado real = inicio da previsão                                          \n",
        "\n",
        "    aux = pred.loc[~pred['y'].isna()][['ds', 'y', 'Vol_Cliente','Vol_NaoCliente']][pri-12:]\n",
        "    aux['Vol_Cli'] = aux['Vol_Cliente']/aux['y']\n",
        "    aux['Vol_NaoCli'] = aux['Vol_NaoCliente']/aux['y']\n",
        "    pred['Vol_Cli'] = pred[pri:]['yhat']*aux['Vol_Cli'].values\n",
        "    pred['Vol_NCli'] = pred[pri:]['yhat']*aux['Vol_NaoCli'].values\n",
        "\n",
        "    pred['Vol_Cliente'].fillna(pred['Vol_Cli'], inplace=True)\n",
        "    pred['Vol_NaoCliente'].fillna(pred['Vol_NCli'], inplace=True)\n",
        "    pred = pred[pred.columns[:-2]]\n",
        "    \n",
        "    return(pred, model, pri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def resultado(regiao='Brasil', filtro='REGIAO3', chave=False):\n",
        "    '''\n",
        "        Resultados dos modelos para cada regiao definina no filtro.\n",
        "            \n",
        "    Parâmetros\n",
        "    ----------\n",
        "        regiao: string\n",
        "            Nome da região a ser considerada no processamento        \n",
        "        filtro: string\n",
        "            Nome da variável(coluna) que formou o agrupamento regional a ser considerado no processamento\n",
        "        chave: Bolean\n",
        "            Variável que define se os dados auxiliares irão compor o modelo(True) ou não(False)\n",
        "    Result:\n",
        "    --------\n",
        "        pred: pd.DataFrame\n",
        "            data freme de previsão associados as componentes do Tamanho de Mercado \n",
        "                (Clientes e Não Clientes)\n",
        "        model: Prophet.model\n",
        "            Modelo prophet ajustado (fitted)\n",
        "        pri: int\n",
        "            posição (index) do último dado real, início da previsão \n",
        "        metric: pd.DataFrame\n",
        "            Dataframe com as métricas de todos os modelos ajustados (metricas_modelos em nb00_Setup_Usinas)\n",
        "            Métricas retornadas: MSE, MAE, RMSEe MAPE\n",
        "\n",
        "    '''\n",
        "    x = ajuste_dados(hist_usinas, safra, filtro=filtro, agrega=chave, regiao=regiao)\n",
        "    df = x.drop(['Vol_Cliente','Vol_NaoCliente'], axis=1)\n",
        "\n",
        "    train, test = dividir_train_test(df, num_meses=12)                              # ver função em nb00_Setup_Usinas\n",
        "    metric = pd.DataFrame(metricas_modelos(df, train, test, order=False))           # ver função em nb00_Setup_Usinas\n",
        "    metric = pd.concat([metric.drop(['metricas'], axis=1), metric['metricas'].apply(pd.Series)], axis=1)\n",
        "    metric = metric.sort_values('MAPE').reset_index(drop=True)\n",
        "\n",
        "    Best_Reg = metric[metric['MAPE'] == metric['MAPE'].min()].iloc[0,:][1]\n",
        "    lista_best = df.columns[0:2].tolist() # usando a variável de Volume\n",
        "    lista_best.extend(Best_Reg)\n",
        "\n",
        "    pred, modelo, pri = processa_modelo(x, df[lista_best])\n",
        "    return(pred, modelo, pri, metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def grafico(df, pri, titulo=''):\n",
        "    '''\n",
        "        Grafico das séries de dados dos modelos de previsão de volume geral incluindo clientes e não clientes.\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dataframe com os dados a serem plotados\n",
        "        pri: int\n",
        "            posição (index) do último dado real, início da previsão\n",
        "        titulo: string\n",
        "            título do gráfico\n",
        "    Result:\n",
        "    --------\n",
        "        fig: objeto plotly.graph_objects\n",
        "            gráfico das séries de dados  \n",
        "    '''\n",
        "    cores = ['green','cadetblue','gray','purple', 'gold']\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(                                   # linha de tendência\n",
        "        x=df['ds'],\n",
        "        y=df['trend'],\n",
        "        line=dict(color='black', width=0.5),\n",
        "        name='Tendência',\n",
        "        #legendgroup = 'Modelo'\n",
        "        #legendgrouptitle_text='Model'      \n",
        "    ))\n",
        "\n",
        "    fig.add_trace(go.Scatter(                                   # Intervalo inferio\n",
        "        x=df['ds'],\n",
        "        y=df['yhat_lower'],\n",
        "        marker={'color': 'rgba(0,0,0,0)'},\n",
        "        showlegend=False,\n",
        "        hoverinfo='none',\n",
        "        #legendgroup = 'Modelo' \n",
        "    ))\n",
        "\n",
        "    fig.add_trace(go.Scatter(                                   # intervalo superior - preenchido\n",
        "        x=df['ds'],\n",
        "        y=df['yhat_upper'],\n",
        "        fill='tonexty',\n",
        "        fillcolor='rgba(255,192,203,0.5)',\n",
        "        line_color='rgba(255,255,255,0)',\n",
        "        name='Confidence',\n",
        "        hoverinfo='none',\n",
        "        mode='none',\n",
        "        #legendgroup = 'Modelo' \n",
        "    ))\n",
        "\n",
        "    fig.add_trace(go.Scatter(                                   # Linha do modelo\n",
        "        x = df['ds'],\n",
        "        y = df['yhat'],\n",
        "        line = dict(color='red', width=2),\n",
        "        name = 'Previsão',\n",
        "        #legendgroup = 'Modelo' \n",
        "    ))\n",
        "       \n",
        "    for c,i in enumerate(df.columns[-4:-2]):                      # linhas dos clientes \n",
        "        fig.add_trace(go.Scatter(\n",
        "            name = i,\n",
        "            x = df['ds'],\n",
        "            y = df[i],\n",
        "            line = {'color': cores[c],'dash':'dot'},\n",
        "            visible=True,\n",
        "            stackgroup='one',\n",
        "            #legendgroup = 'Real' \n",
        "        ))\n",
        "        \n",
        "    fig.add_trace(go.Scatter(                                   # Dados reais\n",
        "        x=df['ds'],\n",
        "        y=df['y'],\n",
        "        mode='lines+markers',\n",
        "        marker={'color': 'rgb(70,130,180)',\n",
        "                'size' : 3,\n",
        "                'line' : {'color': 'rgb(70,130,180)',\n",
        "                        'width': .75}\n",
        "                },\n",
        "        name='Mercado',\n",
        "        #legendgroup = 'Real'\n",
        "        #legendgrouptitle_text='Real1'\n",
        "    ))\n",
        "\n",
        "    fig.add_annotation(\n",
        "            showarrow=False,\n",
        "            text='Gerado em ' + dt.now(tz_SP).strftime(\"%d %b %Y às %H:%M:%S\"),\n",
        "            font=dict(size=12),\n",
        "            align=\"right\",\n",
        "            x=1.0,\n",
        "            y=-0.5,\n",
        "            xref='paper',\n",
        "            yref='paper',\n",
        "            xanchor='right',\n",
        "            yanchor='bottom',)\n",
        "\n",
        "    fig.update_xaxes(matches='x', rangeslider_visible=True, rangeslider_thickness = 0.1)\n",
        "\n",
        "    # Área de previsão\n",
        "    fig.add_vrect(x0=df['ds'][pri], x1=df['ds'].max(), \n",
        "                annotation_text=\"Previsão\",\n",
        "                annotation_position=\"bottom left\",  \n",
        "                annotation_font_size=14,\n",
        "                annotation_font_color=\"white\",\n",
        "                #fillcolor=\"gray\",\n",
        "                opacity=0.15,\n",
        "                line_width=0)\n",
        "\n",
        "    fig.update_layout(\n",
        "        shapes=[\n",
        "            dict(type=\"line\", xref=\"x\", yref=\"y\",\n",
        "                    x0=df['ds'][pri], x1=df['ds'][pri], \n",
        "                    y0=0, y1=df['y'].max()*1.05,\n",
        "                    line=dict(color=\"black\",\n",
        "                            width=2,\n",
        "                            dash=\"dot\")\n",
        "                )]\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        template ='plotly_white',\n",
        "        title = titulo,\n",
        "        #xaxis_title = \"Período\",\n",
        "        yaxis_title = \"Volume (m³)\",\n",
        "        #legend_title = \"Legenda\",\n",
        "        #legend = dict (itemclick = \"toggle\"),\n",
        "        font=dict(family = \"Courier New, monospace\",\n",
        "                  size = 14,\n",
        "                  color = \"royalblue\"),\n",
        "        height=600\n",
        "    )\n",
        "\n",
        "    return(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Leitura dos Dados "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "hist_usinas = pd.read_parquet(abfss_path_enriched + 'usinas/usi03_vendas_impt_mes.parquet',\n",
        "                            storage_options = {'linked_service' : linked_service_enriched})\n",
        "\n",
        "safra = pd.read_parquet(abfss_path_enriched.split('mercado')[0]+'safra_agroconsult/sugarcaneCrop_tratado.parquet',\n",
        "                            storage_options = {'linked_service' : linked_service_enriched})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Adequação do Dataframe de Safras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "safra['data_apuracao'] = pd.to_datetime(safra['data_apuracao'],                 # String to data ignorando erros\n",
        "                                        format='%d/%m/%Y',\n",
        "                                        errors='coerce')\n",
        "safra['sugarcane_crop'] = safra['sugarcane_crop'].astype(float)                 # String to float\n",
        "\n",
        "safra = (safra[(safra['source']=='MAPA') &                                      # Filtro informações do MAPA    \n",
        "               #(safra['product']=='Cana') &                            \n",
        "               (safra['data_apuracao']>='2016-01-01')]                          # Início da série\n",
        "            .sort_values('data_apuracao')\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "reg = {'Norte'       :'N-NE',                                                   # Dic para auxiliar nas novas regionais\n",
        "       'Nordeste'    :'N-NE',\n",
        "       'Sul'         :'CO-S-SE',\n",
        "       'Centro-Oeste':'CO-S-SE',\n",
        "       'Sudeste'     :'CO-S-SE'}\n",
        "\n",
        "safra['REGIAO2'] = [reg[x] if x!='-' else np.nan for x in safra['region']]      # Novas Regiões\n",
        "safra['REGIAO3'] = np.where(safra['state']=='São Paulo', 'SP', safra['REGIAO2'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Correlação entre as Variáveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "regiao = ['Brasil'] + hist_usinas['REGIAO3'].unique().tolist()\n",
        "# fig, axs = plt.subplots(1, 4, figsize=(25, 5), sharey=True)\n",
        "\n",
        "for a, i in enumerate(regiao):\n",
        "    x = ajuste_dados(hist_usinas, safra, filtro='REGIAO3', agrega=True, regiao=i)\n",
        "    df = x.drop(['Vol_Cliente','Vol_NaoCliente'], axis=1)\n",
        "    corr, p_values = stats.spearmanr(df[['y','Açúcar','Cana','Etanol Anidro Total','Etanol Hidratado Total']])\n",
        "    mask = np.invert(np.tril(p_values<0.05)) # plotar somente as correlações significativas\n",
        "    labels = ['Volume de Diesel','Açúcar','Cana','Etanol Anidro Total','Etanol Hidratado Total']\n",
        "\n",
        "    # sns.heatmap(abs(corr), annot=True, cmap='Blues',linewidth=1, fmt='.2f',cbar=False,\n",
        "    #             mask=mask, xticklabels=labels, yticklabels=labels, ax=axs[a])\n",
        "    # axs[a].set_title(i) \n",
        "#fig.show()\n",
        "pd.DataFrame(corr).to_csv(abfss_path_enriched + 'usinas/resultados/to_del.csv', \n",
        "                     storage_options = {'linked_service':linked_service_enriched})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# montar ambiente para salvar resultados\n",
        "try:\n",
        "    mount_dir = '/mount'\n",
        "\n",
        "    mssparkutils.fs.mount( \n",
        "        abfss_path_enriched + 'usinas/resultados', \n",
        "        mount_dir, \n",
        "        {\"linkedService\":linked_service_enriched}\n",
        "    )\n",
        "\n",
        "    job = mssparkutils.env.getJobId()\n",
        "    dir_m = '/synfs/{}{}/'.format(job, mount_dir)\n",
        "except:\n",
        "    print('Falha da montagen do diretório.\\nMétricas e Graficos não serão salvos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "for i in regiao:\n",
        "    # fit dos modelos\n",
        "    pred1, modelo1, pri1, metric1 = resultado(regiao=i, filtro='REGIAO3', chave=False)\n",
        "    pred2, modelo2, pri2, metric2 = resultado(regiao=i, filtro='REGIAO3', chave=True)\n",
        "\n",
        "    # métrica anual\n",
        "    res_mape = mape_ano(pred1).merge(mape_ano(pred2), how='left', on='Ano')\n",
        "    res_mape.columns = ['ANO', 'MAPE_Base-Model', 'MAPE_Best-Model']\n",
        "\n",
        "    # Salvando previsões\n",
        "    arquivo = i + '_' + dt.now(tz_SP).strftime('%Y%m%d')\n",
        "    pred2['data_str'] = pred2['ds'].dt.strftime('%Y-%m-%d').astype('string')\n",
        "    pred2['regiao'] = i                                                                         # Auxilia no join e filtro da visualização\n",
        "    \n",
        "    pred2.to_parquet(abfss_path_enriched + 'usinas/usi05_Previsao_'+ i +'.parquet',             # modelo geral\n",
        "                    storage_options = {'linked_service':linked_service_enriched})\n",
        "    \n",
        "    pred2.to_parquet(abfss_path_enriched + 'usinas/resultados/Previsao_'+ arquivo +'.parquet', \n",
        "                     storage_options = {'linked_service':linked_service_enriched})\n",
        "    \n",
        "    #Salvando Métricas\n",
        "    pd.set_option('display.expand_frame_repr', False)        # Forçar que não exista quebra de páginas no print do dataframe\n",
        "\n",
        "    with open(dir_m + 'Metricas_' + arquivo + '.txt', 'w') as f:\n",
        "        print('RESULTADOS DO MODELO\\n', file=f)\n",
        "        print('Processado em: ' + dt.now(tz_SP).strftime('%d/%m/%Y às %H:%M:%S') + '\\n', file=f)\n",
        "        print('Agrupemento Geográfico: ' + i + '\\n', file=f)\n",
        "        print('Regressores do melhor modelo:', file=f)\n",
        "        print(list(modelo2.extra_regressors.keys()), file=f)\n",
        "        print('\\n', file=f)\n",
        "        print('MAPE anual:', file=f)\n",
        "        print(res_mape, file=f)\n",
        "        print('\\n', file=f)\n",
        "        print('Metricas dos modelos processados\\n', file=f)\n",
        "        print(metric2, file=f)\n",
        "\n",
        "    # Salvando grafico\n",
        "    fig = grafico(pred2, pri2, titulo=(\n",
        "                        'Performance do  Modelo de Previsão para Volume de Diesel<br><sup>'+\n",
        "                        'Usinas Sucroalcooleiras ('+ i + ')</sup>'))\n",
        "    fig = plotly.offline.plot(fig, filename = dir_m + 'Grafico_'+arquivo +'.html', auto_open=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "mssparkutils.fs.unmount(mount_dir) "
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

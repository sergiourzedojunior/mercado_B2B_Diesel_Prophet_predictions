{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Exploração dos melhores modelos da Dinâmica Global do Mercado de Diesel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Setup Inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bibliotecas Utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Manipulação de dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Calculo de estatisticas\n",
        "from scipy import stats\n",
        "\n",
        "# Manipulação de datas\n",
        "from time import strftime\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "# alertas e mensagens de execução\n",
        "import logging\n",
        "import warnings\n",
        "\n",
        "\n",
        "# Prophet para previsão de series de tempo\n",
        "from prophet import Prophet\n",
        "\n",
        "# Medir perdormance dos modelos\n",
        "from sklearn import metrics\n",
        "\n",
        "#MICE(Multiple Imputation by Chained Equations):\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Definições Gerais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# usado para remover as mensagens de output de processamento dos modelos prophet.\n",
        "cmdstanpy_logger = logging.getLogger(\"cmdstanpy\")\n",
        "cmdstanpy_logger.disabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# definção dos diretórios relativos\n",
        "\n",
        "# replace with your container name\n",
        "blob_container_name = 'general' \n",
        "\n",
        "# replace with your relative folder path\n",
        "blob_relative_path_raw = 'raw/mercado_potencial/'\n",
        "blob_relative_path_enriched = 'enriched/mercado_potencial/'\n",
        "\n",
        "\n",
        "# replace with your linked service name\n",
        "linked_service_raw = 'LS_ADLS_RAW_01'\n",
        "linked_service_enriched = 'LS_ADLS_ENRICHED_01'\n",
        "\n",
        "ls_raw = mssparkutils.credentials.getPropertiesAll(linked_service_raw)\n",
        "ls_enriched = mssparkutils.credentials.getPropertiesAll(linked_service_enriched)\n",
        "\n",
        "converter_dic_raw = json.loads(ls_raw)\n",
        "converter_dic_enriched = json.loads(ls_enriched)\n",
        "\n",
        "end_point_raw = (converter_dic_raw['Endpoint'].split(\"/\"))[2]\n",
        "end_point_enriched = (converter_dic_enriched['Endpoint'].split(\"/\"))[2]\n",
        "\n",
        "\n",
        "dir_raw = 'abfss://%s@%s/%s' % (blob_container_name, end_point_raw, blob_relative_path_raw)\n",
        "dir_enriched = 'abfss://%s@%s/%s' % (blob_container_name, end_point_enriched, blob_relative_path_enriched)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# # getting linked services connection string \n",
        "# adls_account_name = 'stedlk01dtandev'  \n",
        "# sas_key = r\"9999\"\n",
        "\n",
        "# dir_enriched = 'abfss://general@stedlk02dtandev.dfs.core.windows.net/enriched/mercado_potencial/'\n",
        "# ls_enriched = 'LS_ADLS_ENRICHED_01'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções Auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dividir_train_test(data, num_meses=12):\n",
        "    '''\n",
        "    Função que divide os dados a serem usados pelos modelos em treino e teste conforme o\n",
        "    padrão pd.DataFrame Prothet contendo as colunas ['ds','y']\n",
        "\n",
        "    Parâmetros:\n",
        "    ------------\n",
        "        data: pd.Dataframe\n",
        "            Dataframe em formato time series do Prothet a ser dividido\n",
        "        num_meses: int\n",
        "            Número de meses usados para teste - 12 meses por padrão\n",
        "    \n",
        "    Retorno:\n",
        "    ----------\n",
        "        train, test: pd.Dataframe\n",
        "            Dataframes de treino e teste\n",
        "    '''\n",
        "    train_data_fim = data['ds'].max() - relativedelta(months=num_meses)\n",
        "    # divisão dos datasets de Treino: train e Teste:test\n",
        "    train = data[data['ds'] <= train_data_fim]\n",
        "    test = data[data['ds'] > train_data_fim]\n",
        "\n",
        "    return (train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def modeloBase():\n",
        "    '''\n",
        "    função modeloBase cria um modelo básico do Prothet\n",
        "\n",
        "    Parâmetros:\n",
        "    ------------\n",
        "        \n",
        "    Retorno:\n",
        "    ----------\n",
        "        model: Prophet model \n",
        "            Modelo Prophet a ser ajustado\n",
        "    '''\n",
        "    model = Prophet(seasonality_mode='multiplicative',\n",
        "                    yearly_seasonality=True, \n",
        "                    weekly_seasonality=False,\n",
        "                    changepoint_range=0.8,\n",
        "                    changepoint_prior_scale=0.05)\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def profecias(modelo, dados, treino, teste):\n",
        "    '''\n",
        "    função professias ajusta o modelo do Prothet\n",
        "\n",
        "    Parâmetros:\n",
        "    ------------\n",
        "        modelo: modelo Prothet\n",
        "            Modelo a ser ajustado (.fit)\n",
        "        dados: pd.DataFrame\n",
        "            Dados a serem ajustados no formato prophet\n",
        "        treino:pd.DataFrame\n",
        "            Dados de treino a serem ajustados no formato prophet\n",
        "        teste: pd.DataFrame\n",
        "            Dados de teste a serem ajustados no formato prophet\n",
        "    Retorno:\n",
        "        predict: pd.DataFrame\n",
        "            Dataframe com os valores previstos \n",
        "    '''\n",
        "    modelo.fit(treino)\n",
        "    future = modelo.make_future_dataframe(periods=len(teste), freq='MS')\n",
        "    future = pd.merge(future, dados, on='ds', how='inner')\n",
        "    future = future.fillna(method='ffill')\n",
        "    \n",
        "    np.random.seed(1000)\n",
        "\n",
        "    predict = modelo.predict(future)\n",
        "    \n",
        "    return(predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def metricas_profecias(y_teste, y_prev, saida='dict', nm_modelo=''):\n",
        "    '''\n",
        "    Calcula as seguintes métricas :\n",
        "        - MSE, MAE, RMSE, MAPE e R²\n",
        "\n",
        "    Parâmetros:\n",
        "    ------------\n",
        "        y_real: float64\n",
        "            Valores reais de Y do banco de teste \n",
        "        y_prev: float64\n",
        "            Valores previstos de Y, informar pd.DataFrame ou Series contendo ['yhat'] que a função resgata a parte equivalente ao teste\n",
        "        saida: string\n",
        "            Formato da saída [print ou dicionario]\n",
        "        nm_modelo: string\n",
        "            Nome do modelo\n",
        "\n",
        "    Retorna:\n",
        "        metricas: dict ou print\n",
        "            MSE, MAE, RMSEe MAPE do modelo\n",
        "    '''\n",
        "    try:\n",
        "        if isinstance(y_prev, pd.DataFrame):\n",
        "            y_prev = y_prev['yhat'][-len(y_teste):]\n",
        "        elif isinstance(y_prev, pd.Series) and y_prev.name == 'yhat':\n",
        "            y_prev = y_prev[-len(y_teste):]\n",
        "    except:\n",
        "        return (print('Parâmetros fora do padrão!\\n'), help(metricas_profecias))\n",
        "\n",
        "    metricas = {'MSE':metrics.mean_squared_error(y_teste, y_prev),\n",
        "                'MAE':metrics.mean_absolute_error(y_teste, y_prev),\n",
        "                'RMSE':np.sqrt(metrics.mean_squared_error(y_teste, y_prev)),\n",
        "                'MAPE':metrics.mean_absolute_percentage_error(y_teste, y_prev)}\n",
        "                    \n",
        "    if saida == 'dict':\n",
        "        return(metricas)\n",
        "    elif saida == 'print':\n",
        "        print('-'*40)\n",
        "        print('          Métricas de Avaliação')\n",
        "        print(nm_modelo)\n",
        "        print('-'*40)\n",
        "        print(' • MSE : {:.5f}'.format(metricas['MSE']))\n",
        "        print(' • MAE : {:.5f}'.format(metricas['MAE']))\n",
        "        print(' • RMSE: {:.5f}'.format(metricas['RMSE']))\n",
        "        print(' • MAPE: {:.5f}'.format(metricas['MAPE']))\n",
        "    else:\n",
        "        return(print('Parâmetros fora do padrão!\\n'), help(metricas_profecias))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def melhor_metrica (x):\n",
        "    \"\"\"Auxilia na viaualização do melhor modelo\n",
        "\n",
        "        Apresenta o melhor modelo - o de menor erro absoluto percentual (MAPE)\n",
        "\n",
        "    Parâmetros:\n",
        "    ----------\n",
        "        x: pd.DataFrame\n",
        "            Dataframe com as metricas dos modelos\n",
        "            \n",
        "    Retorno:\n",
        "    ----------\n",
        "        print do melhor modelo suas métricas e regressores utilizados no modelo\n",
        "    \"\"\"\n",
        "    a = x[x.MAPE == x.MAPE.min()].copy()\n",
        "    a = a.iloc[0,:]\n",
        "    print('                   MELHOR MODELO')\n",
        "    print('Critério: Menor Erro Percentual Absoluto Médio (MAPE)')\n",
        "    print('-'*60)\n",
        "    print('Modelo     : '+ a[0])\n",
        "    print('Regressores: '+', '.join(a[1]))\n",
        "    print('Metricas:')\n",
        "    print(a[2:])\n",
        "    print('-'*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def metricas_modelos(dados, treino, teste):\n",
        "    \"\"\"Metricas dos modelos \n",
        "\n",
        "        Calcula as principais métricas dos modelos de previsão\n",
        "\n",
        "    Parâmetros:\n",
        "    ----------\n",
        "        dados: pd.DataFrame\n",
        "            Dados a serem ajustados no formato prophet\n",
        "        treino:pd.DataFrame\n",
        "            Dados de treino a serem ajustados no formato prophet\n",
        "        teste: pd.DataFrame\n",
        "            Dados de teste a serem ajustados no formato prophet\n",
        "            \n",
        "    Retorno:\n",
        "    ----------\n",
        "        list_result: pd.DataFrame\n",
        "            Dataframe com as métricas de todos os modelos ajustados\n",
        "            Métricas retornadas: MSE, MAE, RMSEe MAPE\n",
        "\n",
        "    \"\"\"\n",
        "    dic_result = {'modelo': 0, 'regressores':'' , 'metricas':{'MSE':0,'MAE':0,'RMSE':0,'MAPE':0,'R2':0}}\n",
        "    list_result = []\n",
        "    vol = dados[dados.columns[1]]\n",
        "    dados.drop(dados.columns[1], axis=1, inplace=True)\n",
        "    regressores = dados.columns.to_list()[2:]       # os 2 primeiros são DataTime e o Y da serie temporal\n",
        "\n",
        "    for indice, regressor in enumerate(regressores):    \n",
        "        mod = modeloBase()\n",
        "        for i in range(indice):                         # passeia por cada lista agregativa\n",
        "            mod.add_regressor(regressores[i], standardize=False)\n",
        "        dic_result['modelo'] = 'modelo_'+str(indice)\n",
        "        dic_result['regressores'] = list(mod.extra_regressors.keys())\n",
        "        \n",
        "        forecast = profecias(mod, dados, treino, teste)\n",
        "        dic_result['metricas'] = metricas_profecias(teste['y'], forecast)\n",
        "        \n",
        "        list_result.append(dic_result.copy())\n",
        "    return(list_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def imputar_dados2 (dim):\n",
        "    '''Imputação de dados\n",
        "\n",
        "        Imputação de dados faltantes que ainda não foram disponibilizados pelas fontes geradoras.\n",
        "        A imputação é feita por meio da média móvel (janela=6).\n",
        "\n",
        "    Parâmetros:\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dados originais       \n",
        "    Retorno:\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dados com os dados imputados.     \n",
        "    '''\n",
        "\n",
        "    lr = LinearRegression()\n",
        "    imp = IterativeImputer(estimator=lr, missing_values=np.nan, max_iter=10, verbose=2, imputation_order='roman', random_state=0)\n",
        "    df = dim.copy()\n",
        "    aux = df.select_dtypes(include=['float64'])\n",
        "    result = pd.DataFrame(imp.fit_transform(aux), columns=aux.columns)\n",
        "\n",
        "    for i in df.columns[df.isnull().any(axis=0)]:\n",
        "        df[i] = np.where(df[i].isnull(), result[i], df[i])\n",
        "\n",
        "    return(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def imputar_dados (df, metodo='mediamovel', janela=6):\n",
        "    '''Imputação de dados\n",
        "\n",
        "        Imputação de dados faltantes que ainda não foram disponibilizados pelas fontes geradoras.\n",
        "        A imputação é feita por meio da média móvel (janela=6).\n",
        "\n",
        "    Parâmetros:\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dados originais\n",
        "        método: String\n",
        "            métodoo de imputação dos dados podendo ser \"mediamovel\" (default), \"media\", \"ultimo\" \n",
        "        janela: Int\n",
        "            Janela de dados utilizados na construção da média móvel. \n",
        "            6 meses - default.            \n",
        "    Retorno:\n",
        "    ----------\n",
        "        df: pd.DataFrame\n",
        "            Dados com os dados imputados.     \n",
        "    '''\n",
        "\n",
        "    df = df.drop('ds', axis=1)\n",
        "    df['temp']=0\n",
        "\n",
        "    if metodo == 'media':\n",
        "        df = df.fillna(df.mean())\n",
        "    elif metodo == 'ultimo':\n",
        "        df = df.fillna(method='ffill') # Fill ultimo\n",
        "    elif metodo =='mediamovel':\n",
        "        for i in df.columns[df.isnull().any(axis=0)]:\n",
        "            df['temp'] = df[i].rolling(janela ,center=True,min_periods=1).mean()\n",
        "            df[i] = np.where(df[i].isnull(), df['temp'], df[i])\n",
        "    else:\n",
        "        print('metodo não existente!')\n",
        "        help(imputar_dados)\n",
        "\n",
        "    #df.reset_index(inplace=True, drop=False)\n",
        "    df.rename(columns={'yhat':'prev_veget'}, inplace=True)\n",
        "    df = df.drop('temp', axis=1)\n",
        "    df.insert(0, 'ds', df.index)\n",
        "    return(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Ajuste dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resgate dos dados a serem usados nos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "ibge_mes   = pd.read_parquet(dir_enriched + 'ibge/IBGE_mes.parquet',\n",
        "                                storage_options = {'linked_service' : linked_service_enriched})\n",
        "diesel_mes = pd.read_parquet(dir_enriched + 'anp/anp_diesel_mes.parquet',\n",
        "                                storage_options = {'linked_service' : linked_service_enriched})\n",
        "bacen_mes  = pd.read_parquet(dir_enriched + 'bacen/BACEN_mes.parquet',\n",
        "                                storage_options = {'linked_service' : linked_service_enriched})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Troca de base do indice de volume de vendas (de jan/2012=100 para jan/2018=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "CF_newbase = diesel_mes['2018-01-01':'2018-01-01']['Indice_ConsumidorFinal'].values[0]\n",
        "TRR_newbase = diesel_mes['2018-01-01':'2018-01-01']['Indice_TRR'].values[0]\n",
        "\n",
        "diesel_mes['Indice_ConsumidorFinal'] = diesel_mes['Indice_ConsumidorFinal']/CF_newbase*100\n",
        "diesel_mes['Indice_TRR'] = diesel_mes['Indice_TRR']/TRR_newbase*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Agregação e ajustes básicos no dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "dinamica = pd.concat([diesel_mes, ibge_mes,bacen_mes],axis=1)\n",
        "\n",
        "# AJUSTES DO DFs\n",
        "dinamica = dinamica['2012-06':] # Data inicio em 2012-06 devido a PNAD_Desocupaçao não possuir dados anteriores\n",
        "dinamica.columns = dinamica.columns.str.replace('consumidor final', 'Volume_ConsumidorFinal')\n",
        "dinamica.columns = dinamica.columns.str.replace('trr','Volume_TRR')\n",
        "dinamica.columns = dinamica.columns.str.replace('data', 'ds')\n",
        "\n",
        "# Linhas não executadas para poder fazer a imputação dos meses rescentes via védia móvel\n",
        "#dinamica = dinamica[dinamica['Volume_ConsumidorFinal'].notnull()]  # Data fim recorte com base nos dados da ANP\n",
        "#dinamica = dinamica[dinamica['PIB_Exportacao'].notnull()] # Data fim recorte com base nos dados do IBGE\n",
        "\n",
        "# definir data final - ultimo mês de dados da ANP - quem define o ultimo mês é a ANP\n",
        "end = dinamica.loc[pd.isna(dinamica['Volume_ConsumidorFinal']), :].index[0]- relativedelta(months=1)\n",
        "end = end.strftime('%Y-%m')\n",
        "\n",
        "dinamica = dinamica[:end]\n",
        "\n",
        "# primeiro dado nan - mes ainda a ser disponibilizado o pib\n",
        "try:\n",
        "    pri = dinamica[dinamica.isnull().T.any()].index[0].strftime('%Y-%m')\n",
        "except:\n",
        "    pass\n",
        "#pri = dinamica.loc[pd.isna(dinamica['PIB_Exportacao']), :].index[0].strftime('%Y-%m') #primeiro nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "dinamica_par = imputar_dados(dinamica, 'mediamovel', 6)             # Dinamica parcial\n",
        "\n",
        "while len(dinamica_par.columns[dinamica_par.isnull().any(axis=0)])!=0:\n",
        "    dinamica_par = imputar_dados(dinamica_par, 'mediamovel', 6)     # Dinamica parcial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Salvando dados da Dinamica Global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "dinamica.to_parquet(dir_enriched + 'volumetria/vol04_dinamica_diesel.parquet', \n",
        "                      storage_options = {'linked_service':linked_service_enriched})\n",
        "\n",
        "dinamica_par.to_parquet(dir_enriched + 'volumetria/vol04_dinamica_diesel_parcial.parquet', \n",
        "                            storage_options = {'linked_service':linked_service_enriched})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##  Separação de Amostras de treino e teste para <br>escolha dos novos modelos a partir de suas métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "lista_CF  = dinamica.columns[~dinamica_par.columns.str.contains('TRR')]\n",
        "lista_TRR = dinamica.columns[~dinamica_par.columns.str.contains('ConsumidorFinal')]\n",
        "\n",
        "df_ConsFinal = dinamica_par[lista_CF]\n",
        "df_TRR = dinamica_par[lista_TRR]\n",
        "\n",
        "df_ConsFinal.rename(columns={'Volume_ConsumidorFinal':'y'}, inplace=True)\n",
        "df_TRR.rename(columns={'Volume_TRR':'y'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_CF, test_CF = dividir_train_test(df_ConsFinal, num_meses=18)\n",
        "train_TRR, test_TRR = dividir_train_test(df_TRR, num_meses=18)\n",
        "test_TRR,x = dividir_train_test(test_TRR, num_meses=6) # remvendo os ultimos 6meses do teste para fixar os 12 meses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Salvando Métricas dos Modelos Ajustados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "CF = pd.DataFrame(metricas_modelos(df_ConsFinal, train_CF, test_CF))\n",
        "TRR = pd.DataFrame(metricas_modelos(df_TRR, train_TRR, test_TRR))\n",
        "\n",
        "CF  = pd.concat([CF.drop(['metricas'], axis=1), CF['metricas'].apply(pd.Series)], axis=1)\n",
        "TRR = pd.concat([TRR.drop(['metricas'], axis=1), TRR['metricas'].apply(pd.Series)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "CF.to_parquet(dir_enriched + 'volumetria/vol04_metricas_global_ConsFinal.parquet', \n",
        "                      storage_options = {'linked_service':linked_service_enriched})\n",
        "\n",
        "TRR.to_parquet(dir_enriched + 'volumetria/vol04_metricas_global_TRR.parquet', \n",
        "                      storage_options = {'linked_service':linked_service_enriched})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "melhor_metrica(CF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "melhor_metrica(TRR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Acesso à Documentação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(dividir_train_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(modeloBase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(profecias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(metricas_profecias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(metricas_modelos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(melhor_metrica)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "help(imputar_dados)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

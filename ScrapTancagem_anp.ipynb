{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "outputs": [],
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "import requests\n",
        "from io import StringIO\n",
        "import re\n",
        "import calendar as cl\n",
        "import locale\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "blob_container_name = 'general'                                             # container name\r\n",
        "\r\n",
        "blob_relative_path_raw = 'raw/mercado_potencial/anp/tancagem_terminais/'    # relative folder path\r\n",
        "blob_relative_path_enriched = 'enriched/mercado_potencial/'                 # relative folder path\r\n",
        "\r\n",
        "linked_service_raw = 'LS_ADLS_RAW_01'                                       # linked service name\r\n",
        "linked_service_enriched = 'LS_ADLS_ENRICHED_01'                             # linked service name\r\n",
        "\r\n",
        "\r\n",
        "ls_raw = mssparkutils.credentials.getPropertiesAll(linked_service_raw)\r\n",
        "ls_enriched = mssparkutils.credentials.getPropertiesAll(linked_service_enriched)\r\n",
        "\r\n",
        "converter_dic_raw = json.loads(ls_raw)\r\n",
        "converter_dic_enriched = json.loads(ls_enriched)\r\n",
        "\r\n",
        "#coletando o endpoint\r\n",
        "end_point_raw = (converter_dic_raw['Endpoint'].split(\"/\"))[2]\r\n",
        "end_point_enriched = (converter_dic_enriched['Endpoint'].split(\"/\"))[2] \r\n",
        "#Utilizado na leitura via metodo mssparkutils\r\n",
        "abfss_path_raw = 'abfss://%s@%s/%s' % (blob_container_name, end_point_raw, blob_relative_path_raw)\r\n",
        "abfss_path_enriched = 'abfss://%s@%s/%s' % (blob_container_name, end_point_enriched, blob_relative_path_enriched)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "url = 'https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/tancagem-do-abastecimento-nacional-de-combustiveis'\n",
        "dir_destino = 'dados/anp/'\n",
        "nm_dado_sv= 'tancagem_terminais'\n",
        "tipo = '.csv'\n",
        "meses = {'janeiro': '01', 'fevereiro': '02', 'março'   : '03', 'marco'   : '03', 'mar'   : '03',\n",
        "         'abril'  : '04', 'maio'     : '05', 'junho'   : '06',\n",
        "         'julho'  : '07', 'agosto'   : '08', 'setembro': '09',\n",
        "         'outubro': '10', 'novembro' : '11', 'dezembro': '12'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {},
      "source": [
        "soup = BeautifulSoup(requests.get(url).text,'html.parser',\n",
        "                     parse_only=SoupStrainer('a'))\n",
        "\n",
        "# dento da url pegar todos os elementos que tenham a tag html 'href' (links)\n",
        "links = []\n",
        "for link in soup:\n",
        "    if link.has_attr('href'):\n",
        "        for file_type in tipo:        \n",
        "            if link['href'].endswith(tipo): # filtro end tipo\n",
        "                links.append(link['href'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "# In[4]: Unificando links\n",
        "\n",
        "links = np.unique(links)\n",
        "arquivo = ['/'.join(y) for y in [x.split('/')[-2:] for x in links]]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "outputs": [],
      "metadata": {},
      "source": [
        "def name_to_save(ls_links = links , nm_suf_sv = nm_dado_sv , tipo_sv = tipo):\n",
        "    try:\n",
        "        locale.setlocale(locale.LC_ALL, \"pt_br\")                                        # Auxilia nos nomes dos meses em [PT-BR]\n",
        "    except:\n",
        "        locale.setlocale(locale.LC_ALL, \"pt_BR\")\n",
        "\n",
        "    # PADRÕES DO regex:\n",
        "    date_pattern = '(\\d{2,4} \\d{1,2} \\d{1,2})'                                          # data tipo %Y %m %d\n",
        "\n",
        "    month_pattern = ['[{}{}]{}(?:{})?'.format(cl.month_name[i][0].upper(),              # nome mês em portugues\n",
        "                                              cl.month_name[i][0].lower(),\n",
        "                                              cl.month_name[i][1:3],\n",
        "                                              cl.month_name[i][3:] ) for i in range(1,13)]\n",
        "    month_pattern = '(?:'+'|'.join(month_pattern)+')'\n",
        "\n",
        "    year_pattern = ''.join('\\d{4}(?!\\d)') # ou \\d{2,4}(?!\\d)\\s*                         # padrão para ano\n",
        "\n",
        "    nomes = [z.replace('_',' ') for \\\n",
        "                z in ['_'.join(y) for \\\n",
        "                    y in [x.split('/')[-2:] for \\\n",
        "                        x in ls_links]]]                                                # coleta os nomes a serem trabalhados\n",
        "\n",
        "    n_data = []\n",
        "    for x in nomes:\n",
        "        if re.findall(date_pattern, x):                                                   # teste na data completa\n",
        "            aux = ''.join(re.findall(date_pattern, x)).replace(' ','')\n",
        "            n_data.append(aux)\n",
        "        else:\n",
        "            ano = re.findall(year_pattern, x)[0] \\\n",
        "                if re.findall(year_pattern, x) \\\n",
        "                    else '0000'     # sem ano                                           # operador ternário para o ano\n",
        "            mes = meses[re.findall(month_pattern, x)[0]] \\\n",
        "                if re.findall(month_pattern, x) \\\n",
        "                    else '00'       # sem mes                                           # operador ternário para o mes\n",
        "            n_data.append(ano+mes+'01')\n",
        "    n_data = [(x +'-'+nm_suf_sv + tipo_sv) for x in n_data]\n",
        "    return(n_data)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "outputs": [],
      "metadata": {},
      "source": [
        "for i in range(len(arquivo)):\n",
        "    file_name = abfss_path_raw + name_to_save(links)[i]\n",
        "    url_ = [y for y in links if y.__contains__(arquivo[i])]\n",
        "    df = requests.get(url=url_[0])\n",
        "    try:\n",
        "        df = df.content.decode('utf-8')\n",
        "    except:\n",
        "        df = df.content.decode('ISO-8859-1') # Arquivos podendo ter falhas no utf-8\n",
        "    \n",
        "    df = pd.read_csv(StringIO(df))\n",
        "    df.to_csv(file_name, index = False, encoding='utf-8',\n",
        "                storage_options = {'linked_service':linked_service_raw})\n",
        "    print(name_to_save(links)[i], ' Salvo com sucesso!  ✔')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# arquivos = [i.path for i in mssparkutils.fs.ls(abfss_path_raw) if i.path.endswith('tancagem_terminais.csv')]\r\n",
        "# arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# pd.read_csv(arquivos[-1],encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "locale.setlocale(locale.LC_ALL, '')"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}